{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slang Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.path.realpath('data.py')\n",
    "parent_directory = parent_directory = os.path.dirname(current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportData:\n",
    "\n",
    "    def __ini__(self):\n",
    "        self.current_directory = current_directory\n",
    "        self.parent_directory = parent_directory\n",
    "\n",
    "    def abbreviations():\n",
    "\n",
    "        data_abbreviations = pd.read_csv(os.path.join(parent_directory,'..','..' ,'live-sentiment-tracker', 'data_raw','Abbreviations_and_Slang.csv'))\n",
    "\n",
    "        return data_abbreviations\n",
    "\n",
    "    def slangs():\n",
    "\n",
    "        data_slangs = pd.read_csv(os.path.join(parent_directory,'..','..', 'live-sentiment-tracker','data_raw','slang.csv'))[['acronym', 'expansion']]\n",
    "\n",
    "        return data_slangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abbreviations = ImportData.abbreviations()\n",
    "data_slangs = ImportData.slangs()\n",
    "\n",
    "remove_list = [13, 15, 16, 27, 41, 63, 66, 67, 112]\n",
    "add_list = [159, 160, 185, 330, 2362]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data + Slang full dataset shape: (108, 2)\n",
      "Data + Slang full dataset null: 0\n",
      "Data + Slang full dataset duplicates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34036/1304852085.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Data + Slang full dataset null: {data_slang_all.isnull().sum()[0]}')\n"
     ]
    }
   ],
   "source": [
    "# Concatenating slang and abbreviation datasets\n",
    "data_slangs.rename(columns = {'acronym':'Abbreviations','expansion':'Text'}, inplace = True)\n",
    "data_slangs = data_slangs[data_slangs.index.isin(add_list)]\n",
    "data_abbreviations.drop(axis=0, labels=remove_list, inplace=True)\n",
    "data_slang_all = pd.concat([data_abbreviations , data_slangs], axis=0)\n",
    "\n",
    "# Drop duplicates and null values\n",
    "data_slang_all.drop_duplicates(inplace=True)\n",
    "data_slang_all.dropna(inplace=True)\n",
    "\n",
    "# Checking\n",
    "print(f'Data + Slang full dataset shape: {data_slang_all.shape}')\n",
    "print(f'Data + Slang full dataset null: {data_slang_all.isnull().sum()[0]}')\n",
    "print(f'Data + Slang full dataset duplicates: {data_slang_all.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slang_all.to_csv('data_slang_all_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming DF into dict for mapping\n",
    "slang_dict = dict(zip(data_slang_all.Abbreviations, data_slang_all.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class SlangTranslation:\n",
    "\n",
    "  def __init__(self, sentence):\n",
    "\n",
    "    self.sentence = sentence\n",
    "\n",
    "  def remove_punctuation(self, sentence):\n",
    "    \"\"\"Iterates through each word of the string and removes punctuation\"\"\"\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "    return sentence\n",
    "\n",
    "  def string_translator(self, sentence):\n",
    "    \"\"\"Iterates through each word of the string and translates them\"\"\"\n",
    "\n",
    "    sentence = ' '.join([slang_dict.get(i, i) for i in sentence.split()])\n",
    "\n",
    "    return sentence\n",
    "\n",
    "  def apply_translator(self, sentence):\n",
    "    \"\"\"Takes the text column as input, outputs the same column translated.\"\"\"\n",
    "\n",
    "    sentence = self.remove_punctuation(sentence)\n",
    "\n",
    "    sentence = self.string_translator(sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader (return overall sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def vader(sentence):\n",
    "    \"\"\"\n",
    "    Function to print sentiment and return overall sentiment\n",
    "    \"\"\"\n",
    "    # Instanciating SentimentIntensityAnalyzer object\n",
    "    vader_model = SentimentIntensityAnalyzer()\n",
    "    sentence = SlangTranslation(sentence).apply_translator(sentence)\n",
    "    # Creating sentiment dict from vader model\n",
    "    sentiment_dict = vader_model.polarity_scores(sentence)\n",
    "\n",
    "    # Printing sentiment percentage\n",
    "    print(f'Sentence: \"{sentence}\"')\n",
    "    print(f\"This sentence is: {sentiment_dict['pos']*100} % positive\")\n",
    "    print(f\"{sentiment_dict['neu']*100} % neutral\")\n",
    "    print(f\"{sentiment_dict['neg']*100} % negative\")\n",
    "\n",
    "    # Conditional to return overall sentiment of the sentence\n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        overall_sentiment = 'The overall sentiment is Positive ğŸ˜Š'\n",
    "        return overall_sentiment\n",
    "\n",
    "    if sentiment_dict['compound'] <= -0.05:\n",
    "        overall_sentiment = 'The overall sentiment is Negative ğŸ˜”'\n",
    "        return overall_sentiment\n",
    "\n",
    "    else:\n",
    "        overall_sentiment = 'The overall sentiment is Neutral ğŸ˜'\n",
    "        return overall_sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader (return vader scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vader_scores(sentence):\n",
    "    \"\"\"\n",
    "    Function to return the dict with the sentiments\n",
    "    \"\"\"\n",
    "    vader_model = SentimentIntensityAnalyzer()\n",
    "    sentence = SlangTranslation(sentence).apply_translator(sentence)\n",
    "    sentiment_dict = vader_model.polarity_scores(sentence)\n",
    "    print(f'Sentence: \"{sentence}\"')\n",
    "    return sentiment_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
